# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1q8TXbkw_J16UkUnf2gvVD4YqBMujHU
"""

# 0. --- (Colab) Required installations (run once) ---
# Agar tum local Jupyter pe ho aur packages installed hain to ye cell skip karo.
!pip install -q xgboost shap imbalanced-learn seaborn

# 1. Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

from imblearn.over_sampling import SMOTE

import shap
import warnings
warnings.filterwarnings("ignore")
sns.set(style="whitegrid")

# 2. Load Data
# Colab: upload the CSV file (WA_Fn-UseC_-Telco-Customer-Churn.csv) to the runtime,
# or set the correct path if local.
# If using Colab: use files.upload() to upload.
from google.colab import files
print("Please upload 'WA_Fn-UseC_-Telco-Customer-Churn.csv' (from Kaggle).")
uploaded = files.upload()
# After upload, get filename:
csv_fname = list(uploaded.keys())[0]
df = pd.read_csv(csv_fname)


df.head()

# 3. Quick EDA (Exploratory Data Analysis)
print("Shape:", df.shape)
print(df.info())
print(df.isnull().sum())

# Replace spaces or inconsistent values (example: ' ' in TotalCharges)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
print("Missing in TotalCharges:", df['TotalCharges'].isna().sum())

# Drop customerID (identifier)
df = df.drop(columns=['customerID'])

# Basic churn distribution
print(df['Churn'].value_counts(normalize=True).rename('proportion'))
sns.countplot(data=df, x='Churn')
plt.title("Churn Distribution")
plt.show()

# tenure distribution
plt.figure(figsize=(8,4))
sns.histplot(df['tenure'], bins=30)
plt.title("Tenure Distribution")
plt.show()

# Contract type vs churn
plt.figure(figsize=(8,4))
sns.countplot(data=df, x='Contract', hue='Churn')
plt.title("Contract Type vs Churn")
plt.show()

# 4. Preprocessing
# Separate numerical and categorical features
num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']
cat_cols = [c for c in df.columns if c not in num_cols + ['Churn']]

print("Numerical:", num_cols)
print("Categorical example:", cat_cols[:10])

# Fill missing TotalCharges (if any) with 0 or tenure*MonthlyCharges as approximation
df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'])

# Encode target
df['Churn'] = df['Churn'].map({'No':0, 'Yes':1})

# Train-test split before SMOTE to avoid data leakage
X = df.drop(columns=['Churn'])
y = df['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
print("Train shape:", X_train.shape, "Test shape:", X_test.shape)

# 5. Build preprocessing pipeline
# OneHotEncode categorical, Scale numeric
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)  # FIX HERE
])

# Fit-transform on training data (we will use pipeline later)
X_train_prep = preprocessor.fit_transform(X_train)
X_test_prep = preprocessor.transform(X_test)

# Column names after one-hot for interpretability
ohe = preprocessor.named_transformers_['cat']
ohe_cols = list(ohe.get_feature_names_out(cat_cols))
feature_names = num_cols + ohe_cols
print("Number of features after encoding:", len(feature_names))

# 6. Handle class imbalance using SMOTE on training data
print("Before SMOTE:", np.bincount(y_train))
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train_prep, y_train)
print("After SMOTE:", np.bincount(y_train_res))

# 7. Train models (Logistic Regression, Random Forest, XGBoost)
# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_res, y_train_res)
y_pred_lr = lr.predict(X_test_prep)

# Random Forest
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train_res, y_train_res)
y_pred_rf = rf.predict(X_test_prep)

# XGBoost
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_model.fit(X_train_res, y_train_res)
y_pred_xgb = xgb_model.predict(X_test_prep)

# 8. Evaluation helper
def print_metrics(y_true, y_pred, model_name="Model"):
    print(f"--- {model_name} ---")
    print("Accuracy :", round(accuracy_score(y_true, y_pred), 4))
    print("Precision:", round(precision_score(y_true, y_pred), 4))
    print("Recall   :", round(recall_score(y_true, y_pred), 4))
    print("F1 Score :", round(f1_score(y_true, y_pred), 4))
    print("Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print(classification_report(y_true, y_pred))

# Print for all
print_metrics(y_test, y_pred_lr, "Logistic Regression")
print_metrics(y_test, y_pred_rf, "Random Forest")
print_metrics(y_test, y_pred_xgb, "XGBoost")

# 9. Feature importance (Random Forest & XGBoost)
# Use our feature_names created earlier
importances = rf.feature_importances_
top_idx = np.argsort(importances)[-15:][::-1]  # top 15
top_features = [feature_names[i] for i in top_idx]
top_importances = importances[top_idx]

plt.figure(figsize=(8,6))
sns.barplot(x=top_importances, y=top_features)
plt.title("Top 15 Feature Importances (Random Forest)")
plt.xlabel("Importance")
plt.show()

# 10. SHAP explanations (for tree model like XGBoost or RandomForest)
# Use a small sample to speed up SHAP computations
explainer = shap.TreeExplainer(xgb_model)  # xgb or rf works
# Convert test features back to DataFrame for shap readability
X_test_df = pd.DataFrame(X_test_prep, columns=feature_names)
sample = X_test_df.sample(n=200, random_state=42)

# Compute SHAP values
shap_values = explainer.shap_values(sample)

# SHAP summary plot (global explanation)
shap.summary_plot(shap_values, sample, feature_names=feature_names, show=True)

# 11. Local explanation example (force plot) for a single customer
idx = sample.index[0]
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[0], sample.iloc[0,:], matplotlib=True)

# 12. Business insights & saving results
# Create a small dataframe with predicted probability and top features (example)
probs = xgb_model.predict_proba(X_test_prep)[:,1]
results_df = X_test.copy()
results_df['true_churn'] = y_test.values
results_df['pred_prob_churn'] = probs
results_df['pred_label'] = (results_df['pred_prob_churn'] >= 0.5).astype(int)
results_df.head()

# Save notebook outputs / models if needed
import joblib
joblib.dump(xgb_model, 'xgb_churn_model.joblib')
joblib.dump(preprocessor, 'preprocessor.joblib')
print("Models saved locally.")

import pandas as pd
from IPython.display import display, HTML

# Example insights dictionary
insights = {
    "Model": ["Logistic Regression", "Random Forest", "XGBoost"],
    "Accuracy": [0.82, 0.89, 0.91],
    "Precision": [0.80, 0.88, 0.90],
    "Recall": [0.78, 0.87, 0.89],
    "F1-Score": [0.79, 0.875, 0.895]
}

import matplotlib.pyplot as plt

# --- Data for the card ---
title = "Client Insight Card"

# Example values (tum apne model ke results se replace kar lena)
metrics = {
    "Model Accuracy": "85%",
    "Churn Rate": "22%",
    "Precision": "80%",
    "Recall": "76%"
}

business_impact = {
    "Retention Increase": "5%",
    "Revenue Impact": "$1.2M",
    "Cost Saving": "$250K"
}

top_features = {
    "Tenure": "High",
    "MonthlyCharges": "Medium",
    "Contract": "High",
    "TechSupport": "Medium"
}

recommendations = [
    "Focus on long-tenure customers",
    "Offer discounts for high monthly charges",
    "Promote annual contracts",
    "Enhance technical support service"
]

# --- Plotting ---
fig, ax = plt.subplots(figsize=(8,6))
ax.axis('off')

# Title
plt.text(0.5, 1.05, title, fontsize=18, fontweight="bold", ha="center", color="black")

# Metrics Table
table_data = [[k, v] for k, v in metrics.items()]
table = ax.table(cellText=table_data, colLabels=["Metric", "Value"],
                 cellLoc="center", loc="upper center", bbox=[0,0.6,1,0.3])
table.auto_set_font_size(False)
table.set_fontsize(10)

# Business Impact
bi_data = [[k, v] for k, v in business_impact.items()]
bi_table = ax.table(cellText=bi_data, colLabels=["Business Impact", "Value"],
                    cellLoc="center", loc="upper center", bbox=[0,0.35,1,0.2])
bi_table.auto_set_font_size(False)
bi_table.set_fontsize(10)

# Top Features
tf_data = [[k, v] for k, v in top_features.items()]
tf_table = ax.table(cellText=tf_data, colLabels=["Feature", "Importance"],
                    cellLoc="center", loc="upper center", bbox=[0,0.15,1,0.2])
tf_table.auto_set_font_size(False)
tf_table.set_fontsize(10)

# Recommendations (as text list)
rec_text = "\n".join([f"- {r}" for r in recommendations])
plt.text(0, -0.05, "Recommendations:\n" + rec_text, fontsize=10, va="top", ha="left", color="black")

plt.show()